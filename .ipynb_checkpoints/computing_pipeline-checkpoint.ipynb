{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "\n",
    "# %autoreload 4\n",
    "from sqlalchemy import Table, Column, String, Integer, Float, Boolean, MetaData, insert, select, BIGINT, Date, DateTime, VARCHAR\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine2 = get_engine(production=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(file):\n",
    "    \n",
    "    batch = pd.read_pickle(file)\n",
    "    \n",
    "    result_lst = []\n",
    "    for idx, group_by_item_id in batch.groupby('ITEM_ID'):\n",
    "        tmp = list(group_by_item_id.groupby('STOCK_ID'))[0][1]    \n",
    "        result_lst.append(get_feature_engineered_bundle(tmp))\n",
    "\n",
    "\n",
    "    results = [result for result in result_lst if result != None]\n",
    "    result_df = pd.DataFrame(results)\n",
    "    \n",
    "    # save feature engineered df\n",
    "    result_df.to_pickle('data/pickle/ivt_item_feature_engineered/%s' % str(file.split('/')[-1]))\n",
    "    \n",
    "    # filter dataframe\n",
    "    filtered_df = get_filtered_fg_df(result_df)\n",
    "\n",
    "    \n",
    "    cleaned_item_ids = filtered_df.item_id.values\n",
    "    cleaned_df = batch[batch['ITEM_ID'].isin(cleaned_item_ids)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_lst =[]\n",
    "    \n",
    "#     save images\n",
    "    save_img(cleaned_df)\n",
    "\n",
    "\n",
    "\n",
    "    for idx, group in cleaned_df.groupby('ITEM_ID'):\n",
    "        try:\n",
    "            df_lst.append(get_sell_amount_by_item_id(group))\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "\n",
    "            \n",
    "    if len(df_lst) > 0:\n",
    "            \n",
    "        result = pd.concat(df_lst)\n",
    "        result[['COLLECT_DAY']] = result.index\n",
    "        \n",
    "        del result['STOCK_AMOUNT_imputed']\n",
    "        del result['STOCK_AMOUNT']\n",
    "        \n",
    "        result.to_sql(con=engine2, name='MWS_COLT_ITEM_SELL_AMT', if_exists='append', flavor='mysql')\n",
    "        logging.warning('done with %s' % str(file))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sell_amount_by_item_id(df, add_sell_amount=False):\n",
    "#     print('hierer')\n",
    "    collect_day = df.COLLECT_DAY.values[0]\n",
    "    reg_id = df.REG_ID.values[0]\n",
    "    \n",
    "    tmp_lst = []\n",
    "    for stock_id, group_df in list(df.groupby('STOCK_ID')):\n",
    "        tmp_lst.append(map_clean_up_target_df(stock_id, group_df))    \n",
    "    result = pd.concat(tmp_lst)\n",
    "    \n",
    "    \n",
    "#     df_pivot = df.pivot_table(index='REG_DT', columns='STOCK_ID', values='STOCK_AMOUNT')\n",
    "#     sell_amount_by_stock = df_pivot.apply(map_clean_up_target_df)\n",
    "\n",
    "#     if add_sell_amount:\n",
    "#         sell_amount_total = sell_amount_by_stock.sum(axis=1)\n",
    "#         result = pd.DataFrame(sell_amount_total)\n",
    "#         result.columns = ['SELL_AMOUNT']\n",
    "#         result['REG_ID'] = reg_id\n",
    "#     else:\n",
    "#         sell_amount_by_stock['REG_DT'] = sell_amount_by_stock.index\n",
    "#         result = pd.melt(sell_amount_by_stock, id_vars=[\"REG_DT\"], var_name=\"STOCK_ID\", value_name=\"SELL_AMOUNT\")\n",
    "\n",
    "    item_id = df.ITEM_ID.values[0]\n",
    "    result['ITEM_ID'] = item_id\n",
    "    result['REG_ID'] = reg_id\n",
    "    result['UPT_DT'] = pd.to_datetime('now')\n",
    "    result['COLLECT_DAY'] = collect_day\n",
    "    result['UPT_ID'] = 'FILTER ALGO'\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_clean_up_target_df(stock_id, group_df):\n",
    "\n",
    "    tmp_df = clean_up_target_df(group_df)[['sell_impute', 'STOCK_AMOUNT', 'STOCK_AMOUNT_imputed']]\n",
    "    tmp_df['STOCK_ID'] = stock_id\n",
    "    tmp_df.columns = ['SELL_AMOUNT', 'STOCK_AMOUNT', 'STOCK_AMOUNT_imputed', 'STOCK_ID']\n",
    "\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.warning(\"it's begin\")\n",
    "files = glob.glob('data/pickle/ivt_item/*.pkl')[:5]\n",
    "engine = get_engine(production=True)\n",
    "add_engine_pidguard(engine)    \n",
    "tmp_lst = Parallel(n_jobs=-1)(map(delayed(process_batch), files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
