{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "import PIL.Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(144, 72, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(48, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(54, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4744 images belonging to 2 classes.\n",
      "Found 2731 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2\n",
    "\n",
    ")\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2\n",
    ")\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'images/dataset/train',  # this is the target directory\n",
    "        target_size=(144, 72),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'images/dataset/validation',\n",
    "        target_size=(144, 72),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 204s 5s/step - loss: 7.8715 - acc: 0.4978 - val_loss: 8.4893 - val_acc: 0.4675\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 203s 5s/step - loss: 7.6205 - acc: 0.5220 - val_loss: 8.4893 - val_acc: 0.4675\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 212s 5s/step - loss: 3.6557 - acc: 0.5005 - val_loss: 0.6806 - val_acc: 0.6913\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 201s 5s/step - loss: 0.7232 - acc: 0.6991 - val_loss: 0.4388 - val_acc: 0.8400\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 201s 5s/step - loss: 0.4368 - acc: 0.8080 - val_loss: 0.3656 - val_acc: 0.8513\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 200s 5s/step - loss: 0.5944 - acc: 0.8180 - val_loss: 0.3886 - val_acc: 0.8713\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 200s 5s/step - loss: 5.7593 - acc: 0.6170 - val_loss: 8.4893 - val_acc: 0.4675\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 197s 5s/step - loss: 7.9999 - acc: 0.4982 - val_loss: 8.4893 - val_acc: 0.4675\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 228s 6s/step - loss: 7.7560 - acc: 0.5135 - val_loss: 8.4893 - val_acc: 0.4675\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 221s 6s/step - loss: 7.9749 - acc: 0.4998 - val_loss: 8.4893 - val_acc: 0.4675\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 231s 6s/step - loss: 8.0190 - acc: 0.4970 - val_loss: 8.4893 - val_acc: 0.4675\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 233s 6s/step - loss: 7.5567 - acc: 0.5260 - val_loss: 8.4893 - val_acc: 0.4675\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 200s 5s/step - loss: 7.7639 - acc: 0.5130 - val_loss: 8.4893 - val_acc: 0.4675\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 197s 5s/step - loss: 8.0589 - acc: 0.4945 - val_loss: 8.4893 - val_acc: 0.4675\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 206s 5s/step - loss: 7.9786 - acc: 0.4995 - val_loss: 8.4893 - val_acc: 0.4675\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 207s 5s/step - loss: 7.8277 - acc: 0.5090 - val_loss: 8.4893 - val_acc: 0.4675\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 207s 5s/step - loss: 7.6842 - acc: 0.5180 - val_loss: 8.4893 - val_acc: 0.4675\n",
      "Epoch 18/100\n",
      "27/40 [===================>..........] - ETA: 57s - loss: 8.0184 - acc: 0.4970 "
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=100,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
