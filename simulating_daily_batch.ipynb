{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "from time import gmtime, strftime\n",
    "from pytz import timezone\n",
    "from datetime import datetime\n",
    "from sqlalchemy import ForeignKey, Table, Column, String, Integer, Float, Boolean, MetaData, select\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epopcon_db = Epopcon_db()\n",
    "\n",
    "wspider_engine = epopcon_db.get_engine(production=True)\n",
    "wspider_temp_engine = epopcon_db.get_engine(production=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_data(target):\n",
    "    \n",
    "    # cluster inventory data points\n",
    "    n_cluster, label = get_label_from_dbscan(target, eps=0.15, min_samples=3)\n",
    "    target['label'] = label\n",
    "    target = target[['STOCK_AMOUNT', 'label', 'REG_DT']]\n",
    "    labels = target.label.unique()\n",
    "    \n",
    "    # resample to a daily scale\n",
    "    target = target.set_index('REG_DT')\n",
    "    target = target.resample('1D').first()\n",
    "    \n",
    "    # placeholding\n",
    "    target['STOCK_AMOUNT_imputed'] = target['STOCK_AMOUNT']\n",
    "\n",
    "    # interpolate data points based on cluster group\n",
    "    for label in labels:\n",
    "        idx = np.where(target.label.values == label)[0]\n",
    "        if len(idx) == 0:\n",
    "            continue\n",
    "        start_v = min(idx)\n",
    "        end_v = max(idx)\n",
    "        target.loc[start_v:end_v+1, 'STOCK_AMOUNT_imputed'] = target['STOCK_AMOUNT'][start_v:end_v+1].interpolate(method='from_derivatives')\n",
    "\n",
    "    # interpolate data points based on global data points\n",
    "    target['STOCK_AMOUNT_imputed'] = target['STOCK_AMOUNT'].interpolate(method='from_derivatives')\n",
    "    \n",
    "    # round STOCK_AMOUNT_imputed to make it cleaner\n",
    "    target['STOCK_AMOUNT_imputed'] = target.STOCK_AMOUNT_imputed.round()\n",
    "\n",
    "    # calculate sell amount \n",
    "    target['sell'] = np.append([0], np.negative(np.diff(target.STOCK_AMOUNT_imputed)))\n",
    "    target.loc[target['sell'].values < 0, 'sell'] = np.nan\n",
    "    target.sell.astype(float)\n",
    "    \n",
    "    # calculate z-score for thresholding\n",
    "    target['zscore'] = np.abs(target.sell - target.sell.mean() / max(0.0001, target.sell.std()))\n",
    "\n",
    "    # get rid of outliers \n",
    "    target.loc[target['zscore'] > 4, 'sell'] = np.nan\n",
    "    \n",
    "    # prepare matrix for data imputation using KNN based on dayofweek\n",
    "    target['weekday_name'] = target.index.dayofweek\n",
    "    X_incomplete = target[['sell', 'weekday_name']].values\n",
    "\n",
    "    # run KNN to calculate sell_impute (imputed version of sell amount)\n",
    "    try:\n",
    "        X_filled_knn = KNN(k=1).complete(X_incomplete)\n",
    "        target['sell_impute'] = X_filled_knn[:,0]\n",
    "    except:\n",
    "        target['sell_impute'] = target['sell']\n",
    "    \n",
    "    # placeholding\n",
    "    target['STOCK_AMOUNT_imputed_trimed'] = target['STOCK_AMOUNT_imputed']\n",
    "    \n",
    "    # get rid of jumpbs\n",
    "    cond = np.append([0], np.negative(np.diff(target.STOCK_AMOUNT_imputed))) < 0\n",
    "    target.loc[cond, 'STOCK_AMOUNT_imputed_trimed'] = np.nan\n",
    "\n",
    "    return target\n",
    "\n",
    "# TODO optimize parameters using ML\n",
    "\n",
    "def get_filtered_fg_df(feature_engineered_df):\n",
    "    static_item_ids = feature_engineered_df.item_id[(feature_engineered_df.std_in_cluster == 0.0)].values\n",
    "    data_df_cleaned = feature_engineered_df[feature_engineered_df.mean_in_cluster.notnull()]\n",
    "    purified_df = data_df_cleaned[(data_df_cleaned.ratio_drop < 0.3)\n",
    "#                           & (data_df_cleaned.ratio_same_value < 0.3)\n",
    "                          & (data_df_cleaned.n_jumps <= 3)\n",
    "                          & (data_df_cleaned.n_days >= 3)\n",
    "#                           & (data_df_cleaned.std_in_cluster > 0.2)\n",
    "                          & (data_df_cleaned.std_in_cluster < 4)\n",
    "                          & (data_df_cleaned.ratio_of_na < 0.5)\n",
    "#                           & (data_df_cleaned.n_unique_stock_id < 50)\n",
    "                                 ]\n",
    "    return purified_df, static_item_ids\n",
    "\n",
    "def get_sell_amount_by_item_id(df, add_sell_amount=False):\n",
    "    \n",
    "    collect_day = df.COLLECT_DAY.values[0]\n",
    "    reg_id = df.REG_ID.values[0]\n",
    "    \n",
    "    imputed_df_lst = []\n",
    "    for stock_id, group_df in list(df.groupby('STOCK_ID')):\n",
    "        \n",
    "        imputed_df = impute_data(group_df)[['sell_impute', 'STOCK_AMOUNT', 'STOCK_AMOUNT_imputed_trimed']]\n",
    "        imputed_df['STOCK_ID'] = stock_id        \n",
    "        imputed_df_lst.append(imputed_df)\n",
    "        \n",
    "    imputed_df = pd.concat(imputed_df_lst)\n",
    "    imputed_df.columns = ['SELL_AMOUNT', 'STOCK_AMOUNT', 'REVISE_STOCK_AMOUNT', 'STOCK_ID']\n",
    "    imputed_df['ITEM_ID'] = df.ITEM_ID.values[0]\n",
    "    imputed_df['REG_ID'] = reg_id\n",
    "    imputed_df['UPT_DT'] = pd.to_datetime(datetime.now(timezone('Asia/Seoul')).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    imputed_df['COLLECT_DAY'] = collect_day\n",
    "    imputed_df['UPT_ID'] = 'FILTER ALGO'\n",
    "\n",
    "    return imputed_df\n",
    "    \n",
    "def insert_extracted_feature(extracted_feature_df):\n",
    "    extracted_feature_df = extracted_feature_df.where((pd.notnull(extracted_feature_df)), None)\n",
    "    query = \"\"\"REPLACE INTO MWS_COLT_ITEM_EXTRACTED_FEATURE %s VALUES %s \"\"\" % (tuple(extracted_feature_df.columns), tuple(['%s' for _ in range(len(extracted_feature_df.columns))]))\n",
    "    query = query.replace(\"'\", \"\")\n",
    "    wspider_temp_engine.execute(query, [tuple(x) for x in extracted_feature_df.values])\n",
    "\n",
    "def insert_sell_amt(sell_amt_df):\n",
    "    sell_amt_df = sell_amt_df.where((pd.notnull(sell_amt_df)), None)\n",
    "    query = \"\"\"REPLACE INTO MWS_COLT_ITEM_SELL_AMT_DEV %s VALUES %s \"\"\" % (tuple(sell_amt_df.columns), tuple(['%s' for _ in range(len(sell_amt_df.columns))]))\n",
    "    query = query.replace(\"'\", \"\")\n",
    "    wspider_temp_engine.execute(query, [tuple(x) for x in sell_amt_df.values])\n",
    "    \n",
    "    query2 = \"\"\"REPLACE INTO MWS_COLT_ITEM_SELL_AMT %s VALUES %s \"\"\" % (tuple(sell_amt_df.columns), tuple(['%s' for _ in range(len(sell_amt_df.columns))]))\n",
    "    query2 = query2.replace(\"'\", \"\")\n",
    "    wspider_engine.execute(query2, [tuple(x) for x in sell_amt_df.values])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily batch\n",
    "\n",
    "DELTA_DAYS = 7\n",
    "today = pd.to_datetime(datetime.now(timezone('Asia/Seoul')).strftime(\"%Y-%m-%d\"))\n",
    "query_date = (today - pd.to_timedelta(DELTA_DAYS, unit='d')).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "tmpp = pd.read_sql_query(\"SELECT item_id FROM MWS_COLT_ITEM_EXTRACTED_FEATURE WHERE condition_clean !=0\", wspider_temp_engine)\n",
    "\n",
    "query = str(tuple([str(item) for item in tmpp.item_id.values]))\n",
    "\n",
    "selected_df = pd.read_sql_query(\"SELECT * FROM MWS_COLT_ITEM_IVT WHERE REG_DT > '%s' AND ITEM_ID in %s\" % (query_date, query), wspider_engine)\n",
    "\n",
    "df_lst =[]\n",
    "\n",
    "for idx, group in selected_df.groupby('ITEM_ID'):\n",
    "    try:\n",
    "        df_lst.append(get_sell_amount_by_item_id(group))\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "if len(df_lst) > 0:\n",
    "\n",
    "    final_result = pd.concat(df_lst)\n",
    "    final_result[['COLLECT_DAY']] = final_result.index\n",
    "#     insert_sell_amt(final_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_sell_amt(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
